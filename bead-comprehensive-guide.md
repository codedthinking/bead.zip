# Bead: Comprehensive Guide to Reproducible Computational Research

**Bead** is a command-line interface (CLI) tool designed to revolutionize how computational research is conducted, shared, and reproduced. It implements a paradigm where discrete computations are packaged as self-contained, versioned units called "beads" that follow the fundamental pattern:

```
output = code(*inputs)
```

## Table of Contents

1. [Core Concepts and Architecture](#core-concepts-and-architecture)
2. [Section 1: Bead Box Management and Basic Operations](#section-1-bead-box-management-and-basic-operations)
3. [Section 2: Dependency Management with Bead Input Commands](#section-2-dependency-management-with-bead-input-commands)
4. [Section 3: Advanced Workflows and Best Practices](#section-3-advanced-workflows-and-best-practices)

---

## Core Concepts and Architecture

### What is a Bead?

A bead is fundamentally a **zip archive** that encapsulates a complete computational unit. Each bead contains:

- **Inputs**: References (content_id hashes) to other beads or external data sources
- **Code**: All scripts, programs, and configuration files needed for computation
- **Output**: The results generated by running the code on the inputs
- **Metadata**: Rich information supporting versioning, linking, and distributed workflows

### Bead Archive Structure

When you extract a bead archive, you'll find this internal structure:

```
bead-archive.zip
├── meta/
│   ├── bead               # Core metadata (JSON format)
│   ├── input.map          # Input dependency mappings
│   └── manifest           # Complete file manifest with checksums
└── data/
    ├── README.md          # Human-readable documentation
    ├── src/               # Source code directory
    │   ├── script1.sh
    │   ├── script2.py
    │   └── ...
    └── output/            # Computation results
        ├── results.csv
        ├── figures.pdf
        └── ...
```

### Standard Workspace Directory Structure

Every bead workspace follows this conventional layout:

```
workspace/
├── .bead-meta/            # Bead metadata directory
│   ├── bead              # Configuration and dependency info
│   └── input.map         # Input mappings (if any)
├── input/                # Input data (managed by bead)
│   ├── dataset1/         # First input dependency
│   │   ├── README.md
│   │   └── data.csv
│   ├── dataset2/         # Second input dependency  
│   │   ├── README.md
│   │   └── processed.txt
│   └── ...
├── output/               # Final computation outputs
│   ├── README.md         # Documentation of outputs
│   ├── results.csv
│   └── figure.pdf
├── temp/                 # Temporary/intermediate files
│   ├── cache/
│   └── working_files/
├── src/                  # Source code
│   ├── download.sh
│   ├── process.py
│   └── analyze.R
├── Makefile              # Build automation (optional)
└── README.md             # Project documentation
```

---

## Section 1: Bead Box Management and Basic Operations

### Understanding Boxes

**Boxes** are Bead's storage and organization system - think of them as repositories or warehouses where beads are stored and catalogued. Each box is simply a directory path where bead archives are kept, but bead manages the indexing and retrieval automatically.

#### Box Management Commands

##### Adding a New Box

```bash
# Basic syntax
bead box add <box-name> <directory-path>

# Real example from the demo
bead box add demo /Users/koren/Downloads/workspace/demo-bead-box
```

**Error Handling**: If the directory doesn't exist, bead will show an error:
```bash
ERROR: "/Users/koren/Downloads/workspace/demo-bead-box" is not an existing directory!
```

**Solution**: Create the directory first:
```bash
mkdir -p /Users/koren/Downloads/workspace/demo-bead-box
bead box add demo /Users/koren/Downloads/workspace/demo-bead-box
```

##### Listing All Boxes

```bash
bead box list
```

**Example Output**:
```
Boxes:
-------------
cat3: /Volumes/Data3/beadbox
cat2: /Users/koren/Downloads/beadbox
private: /Volumes/Data3/cat3-bead-box
demo: /Users/koren/Downloads/workspace/demo-bead-box
```

This shows four different boxes:
- `cat3`: Production box on external drive
- `cat2`: Local development box
- `private`: Confidential data box
- `demo`: Demo/tutorial box

##### Advanced Box Operations

```bash
# Get detailed help
bead box --help

# Available operations:
bead box add        # Define a box
bead box list       # Show known boxes  
bead box forget     # Remove a box from configuration
bead box rewire     # Remap input dependencies
```

**Box Environment Configuration**: Boxes are stored in bead's environment configuration at:
```
/Users/koren/Library/Application Support/bead_cli-6a4d9d98-8e64-4a2a-b6c2-8a753ea61daf
```

### Creating New Beads and Workspaces

#### Creating a Brand New Bead

```bash
# Create and initialize new workspace directory
bead new <DIRECTORY>

# Examples:
bead new my-analysis
bead new /path/to/new-project
bead new experiment-2025
```

**What `bead new` Does**:
1. **Creates** directory with specified name
2. **Initializes** standard bead structure (`.bead-meta/`, `input/`, `output/`, `temp/`, `src/`)
3. **Sets up** empty bead metadata
4. **Ready** for development immediately

#### Checking Workspace Status

```bash
# Show current workspace information  
bead status

# Verbose output with detailed information
bead status -v --verbose

# Check specific workspace
bead status --workspace /path/to/workspace
```

**Status Output Includes**:
- Bead name and workspace location
- Input dependencies and their load status
- Timestamp information
- Missing or outdated inputs (with verbose flag)

### Saving Beads

#### Saving Your Current Workspace

```bash
# Save to a specific box
bead save <box-name>

# Example from demo
bead save demo
```

**Success Output**:
```
Successfully stored bead at /Users/koren/Downloads/workspace/demo-bead-box/german-cities_20250730T153158789876+0200.zip.
```

#### Bead Naming Convention

Saved beads follow this timestamp pattern:
```
<project-name>_<YYYYMMDDTHHMMSSSSSSSS><timezone>.zip

Examples:
german-cities_20250730T153158789876+0200.zip
paper-analysis_20250730T162143891234+0200.zip
data-processing_20250730T094567123456+0200.zip
```

#### Save Command Options

```bash
# Get detailed help
bead save --help

# Key options:
--workspace DIRECTORY, -w DIRECTORY    # Specify workspace directory
--env DIRECTORY, --environment DIRECTORY    # Environment configuration path
```

**Default Behavior**: If you have exactly one box configured, bead will use it automatically. If you have multiple boxes, you must specify which one to use.

### Opening and Inspecting Existing Beads

#### Method 1: Standard Unzip (Read-Only Inspection)

```bash
# Extract the bead archive for inspection
unzip german-cities_20250730T153158789876+0200.zip

# View the contents
tree german-cities_20250730T153158789876+0200/
```

**Archive Information Display**:
When you unzip, you'll see bead's informational header:
```
Archive:  german-cities_20250730T153158789876+0200.zip

This file is a BEAD zip archive.

It is a normal zip file that stores a discrete computation of the form

    output = code(*inputs)

The archive contains

- inputs as part of metadata file: references (content_id) to other BEADs
- code   as files
- output as files
- extra metadata to support
  - linking different versions of the same computation
  - determining the newest version
  - reproducing multi-BEAD computation sequences built by a distributed team

There {is,will be,was} more info about BEADs at

- https://unknot.io
- https://github.com/ceumicrodata/bead
- https://github.com/e3krisztian/bead

----
```

#### Method 2: Bead Develop (Active Development)

```bash
# Unpack bead for development (source files only)
bead develop <bead-reference> [target-directory]

# Examples:
bead develop german-cities_20250730T153158789876+0200.zip
bead develop german-cities_20250730T153158789876+0200.zip my-workspace
bead develop german-cities  # Using bead name instead of filename
```

**Bead Develop Options**:
```bash
bead develop --help

Key options:
-t BEAD_TIME, --time BEAD_TIME          # Specify version timestamp
-x, --extract-output                    # Extract output data (normally not needed)
--env DIRECTORY, --environment DIRECTORY    # Environment configuration
```

**What `bead develop` Does**:
1. **Verifies** the archive integrity
2. **Creates** standard workspace directory structure
3. **Extracts** source code to `src/`
4. **Sets up** `.bead-meta/` configuration
5. **Creates** empty `input/`, `output/`, `temp/` directories
6. **Does NOT** extract output data (unless `-x` flag used)

**Example Output**:
```bash
Verifying archive /Users/koren/Downloads/workspace/demo-bead-box/german-cities_20250730T153158789876+0200.zip ...

# Creates workspace structure:
├── .bead-meta/
│   ├── bead
│   └── input.map
├── input/
├── output/
├── temp/
└── src/
    ├── download.sh
    └── filter_east.sh
```

#### When to Use Each Method

**Use Standard Unzip When**:
- Inspecting bead contents without modifying
- Reviewing output data and results
- Understanding bead structure
- Extracting specific files for reference

**Use Bead Develop When**:
- Planning to modify or extend the computation
- Setting up a new development workspace
- Need proper dependency resolution
- Want to re-run the analysis

### Workspace Management

#### Cleaning Up Workspaces

```bash
# Delete entire workspace
bead zap [workspace-directory]

# Examples:
bead zap                    # Delete current directory workspace
bead zap ./my-analysis      # Delete specific workspace
```

**What `bead zap` Does**:
- Completely removes the workspace directory
- Deletes all data, code, and intermediate files
- **WARNING**: This is irreversible - make sure you've saved important work!

**Note**: The `bead nuke` command exists but is deprecated - use `bead zap` instead.

### Advanced Bead Commands

#### Version Information

```bash
# Show bead program version
bead version
```

#### Extended Metadata Export

```bash
# Export extended metadata to file next to zip archive
bead xmeta [workspace-directory]

# This creates a .xmeta file alongside your bead archive
# Useful for external tools that need detailed bead information
```

#### Workspace Verification

```bash
# Check workspace status
tree .bead-meta/
ls -la input/ output/ temp/ src/

# Verify bead configuration
cat .bead-meta/bead
```

### File Transfer Between Boxes

#### Copying Beads Between Boxes

```bash
# Manual copy example from demo:
cp ../demo-bead-box/german-cities_20250730T153158789876+0200.zip ./

# This allows you to:
# 1. Move beads between different storage locations
# 2. Share beads via file transfer
# 3. Backup beads to multiple locations
# 4. Distribute beads to team members
```

#### Box-to-Box Workflows

```bash
# Typical workflow:
# 1. Work in local development box
bead save local-dev

# 2. Copy to shared team box  
cp ~/.beadbox/local-dev/analysis_*.zip /shared/team-box/

# 3. Copy to production archive box
cp ~/.beadbox/local-dev/analysis_*.zip /archive/production/
```

---

## Section 2: Dependency Management with Bead Input Commands

### Understanding Input Dependencies

Bead's dependency management system is built around **content-based addressing** - each input is identified by a cryptographic hash of its content, ensuring that dependencies are immutable and precisely versioned.

#### Input Directory Structure

```
workspace/input/
├── dependency1/           # First input dependency
│   ├── README.md         # Documentation of this input
│   ├── data.csv          # Actual input data
│   └── metadata.json     # Additional metadata
├── dependency2/           # Second input dependency
│   ├── README.md
│   └── processed.txt
└── .../                  # Additional dependencies
```

### Complete Input Management Commands

The `bead input` command has six main subcommands for comprehensive dependency management:

```bash
bead input {add,delete,map,update,load,unload}
```

#### Adding New Input Dependencies

```bash
# Add and load data from another bead
bead input add <INPUT-NAME> [BEAD-REF]

# Examples:
bead input add german-states                    # Uses german-states as bead name
bead input add population-data census-2024     # Maps population-data to census-2024 bead
bead input add raw-data /path/to/data.zip       # Uses specific archive file

# Advanced options:
bead input add historical-data census-2020 --time 20250730T120000000000+0200
```

**What `bead input add` Does**:
1. **Defines** the dependency relationship in `.bead-meta/bead`
2. **Searches** configured boxes for the specified bead
3. **Extracts** output data from the bead to `input/<INPUT-NAME>/`
4. **Creates** input mapping in `.bead-meta/input.map`
5. **Documents** the dependency for future updates

#### Loading Existing Dependencies

```bash
# Load data from already defined dependency
bead input load <input-name>

# Examples:
bead input load german-states    # Load previously defined dependency
bead input load --all           # Load all defined but missing inputs
```

**Difference between `add` and `load`**:
- `add`: Define new dependency AND load data
- `load`: Load data from existing dependency definition (faster)

#### Updating Input Dependencies

```bash
# Update specific input to newest version
bead input update <input-name>

# Update to specific version/time
bead input update german-states --time 20250730T160000000000+0200

# Update all inputs
bead input update --all

# Examples:
bead input update population-data
bead input update survey-results --time 20250729T090000000000+0200
```

**Update Process**:
1. **Searches** all boxes for newer versions of the input bead
2. **Compares** timestamps and content hashes
3. **Replaces** local input data if newer version found
4. **Updates** `.bead-meta/input.map` with new content_id
5. **Preserves** old data in temporary backup before replacement

#### Remapping Input Sources

```bash
# Change which bead an input loads from
bead input map <input-name> <new-bead-ref>

# Examples:
bead input map german-states german-states-v2
bead input map test-data production-data
bead input map survey-data /path/to/updated-survey.zip
```

**Use Cases for Remapping**:
- Switch from test data to production data
- Point to corrected version of input data
- Update to renamed bead sources
- A/B testing with different input datasets

#### Unloading Input Data

```bash
# Remove input data but keep dependency definition
bead input unload <input-name>

# Examples:
bead input unload large-dataset    # Free disk space
bead input unload temp-processing  # Remove temporary input
```

**When to Unload**:
- Free disk space for large datasets
- Remove temporary inputs no longer needed
- Clean workspace while preserving dependency definitions

#### Deleting Input Dependencies

```bash
# Completely remove input dependency and data
bead input delete <input-name>

# Examples:
bead input delete deprecated-dataset
bead input delete test-input
```

**Warning**: This completely removes:
- Input data from `input/<input-name>/`
- Dependency definition from `.bead-meta/bead`
- Mapping from `.bead-meta/input.map`

### Advanced Dependency Scenarios

#### Scenario 1: Missing Input Dependencies

**Problem**: You develop a bead but some inputs are not available locally.

```bash
# Error when running analysis:
ERROR: Input 'german-states' not found in input/ directory
```

**Solution**:
```bash
# Load the missing input
bead input load german-states

# Verify it was loaded
ls input/german-states/
# Should show:
# README.md  states.txt
```

#### Scenario 2: Input Version Conflicts

**Problem**: Your analysis depends on a specific version of input data, but a newer version is available.

**Detection**:
```bash
bead input check german-states
# Output: New version available: german-states_20250730T160000000000+0200.zip
```

**Options**:
```bash
# Option 1: Update to latest version
bead input update german-states

# Option 2: Pin to specific version (edit .bead-meta/bead)
# Option 3: Create new bead variant with updated inputs
```

#### Scenario 3: Circular Dependencies

**Problem**: Bead A depends on Bead B, which depends on Bead A.

**Detection**: Bead will detect this during dependency resolution:
```bash
ERROR: Circular dependency detected: A -> B -> A
```

**Solutions**:
1. **Refactor** to break the cycle (recommended)
2. **Create intermediate bead** that both can depend on
3. **Merge** the circular beads into a single computation

#### Scenario 4: Private/Confidential Inputs

**Problem**: Some inputs contain sensitive data that cannot be shared.

**Setup**:
```bash
# Create private box for sensitive data
bead box add private /secure/private-data-box

# Save sensitive analysis to private box
bead save private
```

**Sharing Strategy**:
```bash
# Create public version with synthetic data
bead develop sensitive-analysis_*.zip public-version/
# Replace sensitive inputs with synthetic data
# Save public version
cd public-version && bead save public
```

#### Scenario 5: External Data Dependencies

**Problem**: Your analysis depends on data from external APIs or databases.

**Pattern**: Create "data ingestion" beads:
```bash
# Create bead for external data fetching
mkdir external-data-fetch/
cd external-data-fetch/
# Create src/fetch.py to download data
# Save as bead
bead save data-sources

# Use in downstream analysis
cd ../main-analysis/
bead input load external-data-fetch
```

### Input Mapping and Rewiring

#### Understanding Input Maps

The `.bead-meta/input.map` file defines how logical input names map to specific bead content IDs:

```json
{
  "german-states": "bead-content-id-abc123...",
  "population-data": "bead-content-id-def456...",
  "geographic-boundaries": "bead-content-id-ghi789..."
}
```

#### Rewiring Dependencies

```bash
# Remap an input to a different source bead
bead box rewire <input-name> <new-bead-reference>

# Examples:
bead box rewire german-states german-states_20250730T170000000000+0200.zip
bead box rewire population-data census-2024
```

**Use Cases for Rewiring**:
1. **Substitute** test data with production data
2. **Update** to corrected versions of input data
3. **Switch** between different data processing variants
4. **A/B testing** with different input datasets

### Dependency Resolution Algorithm

#### Resolution Process

1. **Parse** `.bead-meta/bead` for input requirements
2. **Check** local `input/` directory for existing data
3. **Verify** content hashes match expected values
4. **Search** configured boxes for missing/outdated inputs
5. **Load** required data from matching beads
6. **Update** local input mappings
7. **Validate** all dependencies are satisfied

#### Conflict Resolution

When multiple versions of an input exist:

```bash
# Bead's resolution priority:
# 1. Exact content_id match (highest priority)
# 2. Latest timestamp for same logical name
# 3. User-specified version with --time flag
# 4. Interactive prompt for ambiguous cases
```

#### Performance Optimization

**Caching Strategy**:
- Content-addressed storage prevents duplicate downloads
- Local input directories cache frequently used data
- Box indexing speeds up dependency searches

**Bandwidth Optimization**:
- Only downloads changed portions of large datasets
- Compressed transfer of bead archives
- Incremental updates when possible

### Bead Web Visualization System

Bead includes a powerful web-based visualization system for understanding and managing complex dependency networks across all your beads.

#### Basic Web Visualization

```bash
# Generate basic dependency graph visualization
bead web png dependency-graph.png
bead web svg dependency-graph.svg

# Open visualization in browser
bead web png graph.png view graph.png
```

#### Web Processing Pipeline

The `bead web` command implements a processing pipeline where each subcommand works on an input graph and yields an output graph:

```bash
# Complete pipeline example
bead web \
  / source-bead1 source-bead2 .. sink-bead1 sink-bead2 / \
  heads \
  color \
  png filtered-graph.png \
  view filtered-graph.png
```

#### Web Subcommands Reference

**Graph Loading and Saving**:
```bash
# Load previously saved web metadata
bead web load filename.web png current-state.png

# Save current web metadata for later use
bead web save network-snapshot.web
```

**Filtering and Analysis**:
```bash
# Filter by source and sink relationships
bead web / data-ingestion processing .. analysis reporting /

# Show only most recent computations per cluster
bead web heads png latest-versions.png

# Assign freshness colors (answers: "Are all inputs at latest version?")
bead web color svg freshness-analysis.svg
```

**Dependency Repair and Maintenance**:
```bash
# Auto-repair broken connections (hackish - use with caution)
bead web auto-rewire save repaired.web

# Generate rewiring options file for manual review
bead web rewire-options repair-options.json

# Apply reviewed rewiring options
bead web rewire repair-options.json save fixed-network.web
```

**Visualization Output Formats**:
```bash
# PNG format (good for presentations)
bead web png network-overview.png

# SVG format (scalable, good for documents)  
bead web svg detailed-network.svg

# Open any visualization file in browser
bead web view network-overview.png
```

#### Web Pipeline Use Cases

**Project Health Assessment**:
```bash
# Check if all beads use latest input versions
bead web color png health-check.png view health-check.png
```

**Dependency Impact Analysis**:
```bash
# See what depends on a specific data source
bead web / raw-dataset .. / png impact-analysis.png
```

**Network Cleanup**:
```bash
# Show only actively used beads (remove obsolete versions)
bead web heads color png clean-network.png
```

**Broken Dependency Repair**:
```bash
# Step 1: Identify problems and solutions
bead web rewire-options problems.json

# Step 2: Edit problems.json manually to select preferred solutions

# Step 3: Apply fixes
bead web rewire problems.json png fixed-network.png
```

#### Web Visualization Best Practices

1. **Regular Health Checks**: Use `color` command to identify stale dependencies
2. **Impact Analysis**: Before major changes, use filtering to see affected beads
3. **Cleanup Maintenance**: Use `heads` to focus on current work and identify obsolete beads
4. **Documentation**: Save network snapshots before major reorganizations
5. **Team Coordination**: Share visualizations to communicate project structure

---

## Section 3: Advanced Workflows and Best Practices

### Multi-Project Dependency Workflows

#### Complex Dependency Graph Example

Based on the demo screencast, here's the dependency structure:

```
┌─────────────────┐    ┌──────────────────┐
│   german-states │    │   private-data   │
│                 │    │                  │
│ Input: Wikipedia│    │ Input: Confidential│
│ Output: states.txt│  │ Output: filtered_data.dta│
└─────────────────┘    └──────────────────┘
         │                       │
         ▼                       │
┌─────────────────┐              │
│  german-cities  │              │
│                 │              │
│ Input: german-  │              │
│        states   │              │
│ Output: cities.txt│            │
└─────────────────┘              │
         │                       │
         ▼                       ▼
    ┌─────────────────────────────┐
    │          paper              │
    │                             │
    │ Input: german-cities,       │
    │        private-data         │
    │ Output: figure.pdf          │
    └─────────────────────────────┘
```

#### Implementing the Workflow

**Step 1: German States Data Collection**
```bash
mkdir german-states
cd german-states
# Standard bead directory structure created

# Create src/extract_states.py
cat > src/extract_states.py << 'EOF'
#!/usr/bin/env python3
import requests
import re

# Download German states data from Wikipedia
url = "https://en.wikipedia.org/wiki/States_of_Germany"
response = requests.get(url)
# Parse and extract state information
# Save to output/states.txt
EOF

# Run the extraction
python src/extract_states.py

# Save as bead
bead save demo
cd ..
```

**Step 2: German Cities Processing** 
```bash
mkdir german-cities
cd german-cities

# Set up dependency on german-states
bead input load german-states

# Create processing scripts
cat > src/download.sh << 'EOF'
#!/bin/bash
curl -sLo temp/raw_cities.txt "https://en.wikipedia.org/wiki/List_of_cities_and_towns_in_Germany"
EOF

cat > src/filter_east.sh << 'EOF' 
#!/bin/bash
# Filter cities by East German states using input/german-states/states.txt
grep -f input/german-states/states.txt temp/raw_cities.txt > output/cities.txt
EOF

# Execute pipeline
make all  # or bash src/download.sh && bash src/filter_east.sh

# Save processed data
bead save demo
cd ..
```

**Step 3: Private Data Processing**
```bash
mkdir private-data
cd private-data

# Process confidential data
cat > src/process_confidential.do << 'EOF'
* Stata script for processing confidential microdata
use "confidential_source.dta", clear
* Apply privacy filters and aggregations
keep if privacy_ok == 1
collapse (mean) outcome, by(region)
save "output/filtered_data.dta", replace
EOF

stata -b do src/process_confidential.do

# Save to private box
bead save private
cd ..
```

**Step 4: Paper Generation**
```bash  
mkdir paper
cd paper

# Load both dependencies
bead input load german-cities
bead input load private-data

# Create visualization script
cat > src/plot.sh << 'EOF'
#!/bin/bash
# Combine city data with private analysis results
python3 src/generate_figure.py \
  --cities input/german-cities/cities.txt \
  --data input/private-data/filtered_data.dta \
  --output output/figure.pdf
EOF

# Generate final output
bash src/plot.sh

# Save final paper bead
bead save demo
cd ..
```

### Team Collaboration Patterns

#### Pattern 1: Distributed Development

**Scenario**: Multiple researchers working on different components of a large analysis.

**Setup**:
```bash
# Each team member has their own development box
bead box add alice-dev /home/alice/bead-workspace
bead box add bob-dev /home/bob/bead-workspace  
bead box add shared-team /shared/team-beads
```

**Workflow**:
```bash
# Alice works on data cleaning
cd alice-analysis/
# ... develop and test ...
bead save alice-dev

# Share with team
cp ~/.bead/alice-dev/data-cleaning_*.zip /shared/team-beads/

# Bob loads Alice's work as input
cd bob-analysis/
bead input load data-cleaning  # Automatically finds Alice's bead
# ... build on Alice's work ...
bead save bob-dev
```

#### Pattern 2: Staged Release Pipeline

**Development → Testing → Production**

```bash
# Development box
bead box add dev /workspace/development
# Testing box  
bead box add test /workspace/testing
# Production box
bead box add prod /workspace/production

# Development workflow
cd my-analysis/
bead save dev

# Promote to testing
cp /workspace/development/analysis_*.zip /workspace/testing/
cd testing-workspace/
bead develop analysis_latest.zip
# Run validation tests
make test
bead save test

# Promote to production
cp /workspace/testing/analysis_*.zip /workspace/production/
```

#### Pattern 3: Fork-and-Merge

**Scenario**: Experimenting with different approaches to the same analysis.

```bash
# Create base analysis
cd base-analysis/
bead save main

# Create experimental fork
bead develop base-analysis_*.zip experiment-v1/
cd experiment-v1/
# Modify approach
bead save experiments

# Create second fork
bead develop base-analysis_*.zip experiment-v2/  
cd experiment-v2/
# Try different approach
bead save experiments

# Compare results and merge best approach back to main
# Manual process - bead doesn't enforce git-like merging
```

### Integration with Existing Tools

#### Integration with Make

**Advanced Makefile Integration**:
```makefile
# Makefile for bead-enabled project
.PHONY: all clean inputs save-bead

# Default target
all: output/results.csv output/figure.pdf

# Ensure inputs are loaded
inputs:
	@echo "Loading input dependencies..."
	@bead input load raw-data || echo "Input raw-data already loaded"
	@bead input load parameters || echo "Input parameters already loaded"

# Main analysis depends on inputs
output/results.csv: inputs src/analyze.py
	python src/analyze.py

# Visualization depends on results
output/figure.pdf: output/results.csv src/plot.R
	Rscript src/plot.R

# Save current state as bead
save-bead: all
	bead save production

# Clean temporary files but preserve inputs and outputs
clean:
	rm -rf temp/*
	
# Nuclear clean - remove everything except source
clean-all:
	rm -rf temp/* output/* input/*
```

#### Integration with Git

**.gitignore for Bead Projects**:
```gitignore
# Bead-specific ignores
input/          # Input data managed by bead
temp/           # Temporary files
*.zip           # Bead archives (store in boxes, not git)

# Keep source and configuration
!src/
!.bead-meta/
!Makefile
!README.md

# Standard ignores
.DS_Store
*.pyc
__pycache__/
.Rhistory
*.log
```

**Git Workflow with Bead**:
```bash
# Initialize git in bead workspace
git init
git add src/ .bead-meta/ Makefile README.md
git commit -m "Initial bead project structure"

# Work on analysis
# ... edit src/analysis.py ...
git add src/analysis.py
git commit -m "Update analysis methodology"

# Save computation state
bead save development

# Both git and bead track different aspects:
# - Git: source code evolution
# - Bead: data dependencies and computational reproducibility
```

#### Integration with Conda/Virtual Environments

**Managing Software Dependencies**:
```bash
# Create environment specification
cat > environment.yml << 'EOF'
name: my-analysis
dependencies:
  - python=3.9
  - pandas
  - matplotlib  
  - pip
  - pip:
    - specialized-package==1.2.3
EOF

# Include in source control
git add environment.yml

# Activate environment before bead operations
conda env create -f environment.yml
conda activate my-analysis
bead develop my-analysis_*.zip
```

### Performance and Scalability

#### Large Dataset Strategies

**Problem**: Working with datasets too large for standard bead archives.

**Solution 1: Data Splitting**
```bash
# Split large dataset into chunks
mkdir data-preparation/
cd data-preparation/
# Create src/split_data.py to chunk large files
# Save splitting logic as bead
bead save data-tools

# Create separate beads for each chunk
for chunk in chunk_*.csv; do
  mkdir "process-${chunk}"
  cd "process-${chunk}"
  ln -s "../${chunk}" input/data.csv
  # Process chunk
  bead save processing
  cd ..
done
```

**Solution 2: External Storage References**
```bash
# Store large data externally, reference in bead
cat > src/load_external.py << 'EOF'
# Reference external storage (S3, network drives, etc.)
import boto3
s3 = boto3.client('s3')
s3.download_file('my-bucket', 'large-dataset.parquet', 'temp/data.parquet')
EOF

# Bead contains logic and metadata, not the large data
```

#### Parallel Processing Workflows

**Multi-Core Processing within Beads**:
```bash
cat > src/parallel_analysis.py << 'EOF'
from multiprocessing import Pool
import pandas as pd

def process_chunk(chunk_id):
    # Process individual chunk
    chunk = pd.read_csv(f'input/data/chunk_{chunk_id}.csv')
    result = chunk.groupby('category').sum()
    return result

# Process all chunks in parallel
with Pool() as pool:
    results = pool.map(process_chunk, range(10))
    
# Combine results
final_result = pd.concat(results)
final_result.to_csv('output/combined_results.csv')
EOF
```

**Multi-Bead Parallel Workflows**:
```bash
# Process multiple beads concurrently
parallel -j 4 "cd {} && make all && bead save batch-processing" ::: analysis_*/

# Or with explicit bead operations
find . -name "*_input.zip" | parallel -j 8 "bead develop {} {/.}_workspace && cd {/.}_workspace && make all && bead save batch-results"
```

### Quality Assurance and Testing

#### Bead Validation Strategies

**Automated Testing Pipeline**:
```bash
cat > src/test_analysis.py << 'EOF'
#!/usr/bin/env python3
import unittest
import pandas as pd
import os

class TestAnalysis(unittest.TestCase):
    def setUp(self):
        # Verify inputs are loaded
        self.assertTrue(os.path.exists('input/raw-data'))
        
    def test_output_exists(self):
        # Run analysis
        os.system('python src/main_analysis.py')
        self.assertTrue(os.path.exists('output/results.csv'))
        
    def test_output_quality(self):
        results = pd.read_csv('output/results.csv')
        # Validate data quality
        self.assertGreater(len(results), 0)
        self.assertFalse(results.isnull().any().any())

if __name__ == '__main__':
    unittest.main()
EOF

# Include testing in Makefile
cat >> Makefile << 'EOF'
test: inputs
	python src/test_analysis.py
	
save-bead: test
	bead save production
EOF
```

#### Reproducibility Verification

**Cross-Platform Testing**:
```bash
# Test bead on different systems
# System 1 (Linux)
bead develop analysis_*.zip test-linux/
cd test-linux && make all

# System 2 (macOS)  
bead develop analysis_*.zip test-macos/
cd test-macos && make all

# Compare outputs
diff test-linux/output/ test-macos/output/
```

**Long-term Reproducibility**:
```bash
# Document software versions in bead
cat > src/environment_snapshot.sh << 'EOF'
#!/bin/bash
echo "=== Software Environment ===" > output/environment.txt
python --version >> output/environment.txt
R --version >> output/environment.txt
conda list >> output/environment.txt
pip freeze >> output/environment.txt
EOF

# Run before main analysis
bash src/environment_snapshot.sh
python src/main_analysis.py
```

### Security and Access Control

#### Sensitive Data Handling

**Private Box Configuration**:
```bash
# Create encrypted private box
mkdir /secure/encrypted-beads
chmod 700 /secure/encrypted-beads
bead box add private-secure /secure/encrypted-beads
```

**Data Sanitization for Sharing**:
```bash
cat > src/create_public_version.py << 'EOF'
#!/usr/bin/env python3
import pandas as pd
import numpy as np

# Load private data
private_data = pd.read_csv('input/confidential/sensitive.csv')

# Create synthetic version preserving statistical properties
public_data = private_data.copy()
# Replace sensitive columns with synthetic data
public_data['personal_id'] = np.random.randint(1000000, 9999999, len(public_data))
public_data['salary'] = np.random.normal(
    private_data['salary'].mean(), 
    private_data['salary'].std(), 
    len(public_data)
)

# Save sanitized version
public_data.to_csv('output/public_data.csv', index=False)
EOF
```

#### Access Audit Trails

**Tracking Bead Usage**:
```bash
cat > src/log_access.py << 'EOF'
#!/usr/bin/env python3
import datetime
import getpass
import socket

# Log access to sensitive bead
with open('temp/access_log.txt', 'a') as f:
    f.write(f"{datetime.datetime.now()}: {getpass.getuser()}@{socket.gethostname()}\n")
EOF

# Include in analysis pipeline
python src/log_access.py
python src/main_analysis.py
```

### Troubleshooting and Recovery

#### Common Issues and Solutions

**Issue 1: Corrupted Bead Archive**
```bash
# Verify bead integrity
unzip -t analysis_*.zip

# If corrupted, restore from backup box
bead box list
cp /backup/bead-box/analysis_*.zip ./
```

**Issue 2: Missing Dependencies**
```bash
# Diagnose missing inputs
cat .bead-meta/bead | grep -A 5 "inputs"

# Search all boxes for missing dependencies
for box in $(bead box list | grep ":" | cut -d: -f1); do
  echo "Searching box: $box"
  find /path/to/$box -name "*dependency-name*"
done
```

**Issue 3: Version Conflicts**
```bash
# Check current input versions
bead input list

# See available versions in boxes
find /path/to/boxes -name "*input-name*" -exec basename {} \;

# Resolve by specifying exact version
bead input load input-name --time 20250730T120000000000+0200
```

#### Disaster Recovery

**Backup Strategy**:
```bash
# Regular backup of all boxes
rsync -av /primary/bead-boxes/ /backup/bead-boxes/

# Export bead index for recovery
bead box list > bead-boxes-backup.txt
```

**Recovery Process**:
```bash
# Restore box configuration
while read line; do
  name=$(echo $line | cut -d: -f1)
  path=$(echo $line | cut -d: -f2 | xargs)
  bead box add $name $path
done < bead-boxes-backup.txt

# Verify recovery
bead box list
```

This comprehensive guide covers the full spectrum of Bead's capabilities, from basic box management to advanced enterprise workflows. The tool's strength lies in its simplicity of concept (discrete computational units) combined with powerful dependency management and sharing capabilities.